# ğŸ§° Oozie + Hadoop + Hive + Zookeeper - Dockerized Big Data Stack

This setup runs Apache Oozie with Hadoop HDFS, Hive, and Zookeeper using Docker Compose. It also supports uploading and running Oozie workflows.

---

## ğŸ“ Folder Structure

```
.
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ oozie-wf-shell
    â”œâ”€â”€ action.sh
    â”œâ”€â”€ job.properties
    â””â”€â”€ workflow.xml
â”œâ”€â”€ README.md
â””â”€â”€ hadoop-config
    â””â”€â”€ core-site.xml
```

---

## ğŸ“¦ Prerequisites

- Docker
- Docker Compose
- Basic familiarity with Hadoop and Oozie

---


## ğŸš€ 1. Start Containers

```bash
docker-compose up -d
```

---

## ğŸ“¤ 2. Upload Oozie Workflow to HDFS

Upload oozie-shell-wf folder to HDFS:

```bash
hdfs dfs -mkdir -p /user/hadoop/oozie-apps/shell
hdfs dfs -put workflow.xml echo.sh /user/hadoop/oozie-apps/shell/
```

---

## â–¶ï¸ 4. Run Oozie Job

Inside the container Run Oozie Job:

```bash
docker exec -it hadoop-oozie bash

cd oozie-wf-shell/
chmod +x echo.sh
oozie job -oozie http://localhost:11000/oozie -config job.properties -run
```

---

## ğŸ“¬ Connect

- Oozie Web UI: [http://localhost:11000/oozie](http://localhost:11000/oozie)
- HDFS UI (NameNode): [http://localhost:50070](http://localhost:50070)

---